{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 39, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ae2517b61b41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://archive.ics.uci.edu/ml/datasets/SPECTF+Heart\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 39, saw 2\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/datasets/SPECTF+Heart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(wine.data, columns = wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(wine.target, columns = [\"TARGET\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([features, target], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.380000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.12</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.32</td>\n",
       "      <td>16.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.81</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.75</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.39</td>\n",
       "      <td>11.4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.38</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.96</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.70</td>\n",
       "      <td>17.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.30</td>\n",
       "      <td>1.92</td>\n",
       "      <td>2.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.83</td>\n",
       "      <td>1.57</td>\n",
       "      <td>2.62</td>\n",
       "      <td>20.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.72</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.19</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.48</td>\n",
       "      <td>16.5</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.86</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.64</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.66</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.36</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.06</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.71</td>\n",
       "      <td>780.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.93</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.65</td>\n",
       "      <td>18.6</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.52</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.71</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.36</td>\n",
       "      <td>16.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.52</td>\n",
       "      <td>17.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.930000</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>1.12</td>\n",
       "      <td>3.82</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.05</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.22</td>\n",
       "      <td>25.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.20</td>\n",
       "      <td>830.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.62</td>\n",
       "      <td>16.1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.87</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>19.4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.40</td>\n",
       "      <td>915.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>13.32</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.420000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>650.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.33</td>\n",
       "      <td>550.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>13.50</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.62</td>\n",
       "      <td>24.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.30</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>12.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.47</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>425.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>13.23</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>10.520000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.51</td>\n",
       "      <td>675.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.55</td>\n",
       "      <td>640.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>13.17</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>725.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>13.84</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.010000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.64</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>12.45</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.64</td>\n",
       "      <td>27.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>880.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "      <td>660.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "      <td>620.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>12.36</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.58</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>12.85</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.58</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.580000</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11</td>\n",
       "      <td>570.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>12.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.35</td>\n",
       "      <td>18.5</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.75</td>\n",
       "      <td>675.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>13.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>615.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>13.73</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.26</td>\n",
       "      <td>22.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.620000</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>13.45</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.60</td>\n",
       "      <td>23.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.46</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.56</td>\n",
       "      <td>695.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12.82</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10.260000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>685.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>13.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.69</td>\n",
       "      <td>24.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>630.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>12.20</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>510.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>12.77</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.28</td>\n",
       "      <td>19.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.899999</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.63</td>\n",
       "      <td>470.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>14.16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.24</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>660.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "5      14.20        1.76  2.45               15.2      112.0           3.27   \n",
       "6      14.39        1.87  2.45               14.6       96.0           2.50   \n",
       "7      14.06        2.15  2.61               17.6      121.0           2.60   \n",
       "8      14.83        1.64  2.17               14.0       97.0           2.80   \n",
       "9      13.86        1.35  2.27               16.0       98.0           2.98   \n",
       "10     14.10        2.16  2.30               18.0      105.0           2.95   \n",
       "11     14.12        1.48  2.32               16.8       95.0           2.20   \n",
       "12     13.75        1.73  2.41               16.0       89.0           2.60   \n",
       "13     14.75        1.73  2.39               11.4       91.0           3.10   \n",
       "14     14.38        1.87  2.38               12.0      102.0           3.30   \n",
       "15     13.63        1.81  2.70               17.2      112.0           2.85   \n",
       "16     14.30        1.92  2.72               20.0      120.0           2.80   \n",
       "17     13.83        1.57  2.62               20.0      115.0           2.95   \n",
       "18     14.19        1.59  2.48               16.5      108.0           3.30   \n",
       "19     13.64        3.10  2.56               15.2      116.0           2.70   \n",
       "20     14.06        1.63  2.28               16.0      126.0           3.00   \n",
       "21     12.93        3.80  2.65               18.6      102.0           2.41   \n",
       "22     13.71        1.86  2.36               16.6      101.0           2.61   \n",
       "23     12.85        1.60  2.52               17.8       95.0           2.48   \n",
       "24     13.50        1.81  2.61               20.0       96.0           2.53   \n",
       "25     13.05        2.05  3.22               25.0      124.0           2.63   \n",
       "26     13.39        1.77  2.62               16.1       93.0           2.85   \n",
       "27     13.30        1.72  2.14               17.0       94.0           2.40   \n",
       "28     13.87        1.90  2.80               19.4      107.0           2.95   \n",
       "29     14.02        1.68  2.21               16.0       96.0           2.65   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "148    13.32        3.24  2.38               21.5       92.0           1.93   \n",
       "149    13.08        3.90  2.36               21.5      113.0           1.41   \n",
       "150    13.50        3.12  2.62               24.0      123.0           1.40   \n",
       "151    12.79        2.67  2.48               22.0      112.0           1.48   \n",
       "152    13.11        1.90  2.75               25.5      116.0           2.20   \n",
       "153    13.23        3.30  2.28               18.5       98.0           1.80   \n",
       "154    12.58        1.29  2.10               20.0      103.0           1.48   \n",
       "155    13.17        5.19  2.32               22.0       93.0           1.74   \n",
       "156    13.84        4.12  2.38               19.5       89.0           1.80   \n",
       "157    12.45        3.03  2.64               27.0       97.0           1.90   \n",
       "158    14.34        1.68  2.70               25.0       98.0           2.80   \n",
       "159    13.48        1.67  2.64               22.5       89.0           2.60   \n",
       "160    12.36        3.83  2.38               21.0       88.0           2.30   \n",
       "161    13.69        3.26  2.54               20.0      107.0           1.83   \n",
       "162    12.85        3.27  2.58               22.0      106.0           1.65   \n",
       "163    12.96        3.45  2.35               18.5      106.0           1.39   \n",
       "164    13.78        2.76  2.30               22.0       90.0           1.35   \n",
       "165    13.73        4.36  2.26               22.5       88.0           1.28   \n",
       "166    13.45        3.70  2.60               23.0      111.0           1.70   \n",
       "167    12.82        3.37  2.30               19.5       88.0           1.48   \n",
       "168    13.58        2.58  2.69               24.5      105.0           1.55   \n",
       "169    13.40        4.60  2.86               25.0      112.0           1.98   \n",
       "170    12.20        3.03  2.32               19.0       96.0           1.25   \n",
       "171    12.77        2.39  2.28               19.5       86.0           1.39   \n",
       "172    14.16        2.51  2.48               20.0       91.0           1.68   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29         5.640000  1.04   \n",
       "1          2.76                  0.26             1.28         4.380000  1.05   \n",
       "2          3.24                  0.30             2.81         5.680000  1.03   \n",
       "3          3.49                  0.24             2.18         7.800000  0.86   \n",
       "4          2.69                  0.39             1.82         4.320000  1.04   \n",
       "5          3.39                  0.34             1.97         6.750000  1.05   \n",
       "6          2.52                  0.30             1.98         5.250000  1.02   \n",
       "7          2.51                  0.31             1.25         5.050000  1.06   \n",
       "8          2.98                  0.29             1.98         5.200000  1.08   \n",
       "9          3.15                  0.22             1.85         7.220000  1.01   \n",
       "10         3.32                  0.22             2.38         5.750000  1.25   \n",
       "11         2.43                  0.26             1.57         5.000000  1.17   \n",
       "12         2.76                  0.29             1.81         5.600000  1.15   \n",
       "13         3.69                  0.43             2.81         5.400000  1.25   \n",
       "14         3.64                  0.29             2.96         7.500000  1.20   \n",
       "15         2.91                  0.30             1.46         7.300000  1.28   \n",
       "16         3.14                  0.33             1.97         6.200000  1.07   \n",
       "17         3.40                  0.40             1.72         6.600000  1.13   \n",
       "18         3.93                  0.32             1.86         8.700000  1.23   \n",
       "19         3.03                  0.17             1.66         5.100000  0.96   \n",
       "20         3.17                  0.24             2.10         5.650000  1.09   \n",
       "21         2.41                  0.25             1.98         4.500000  1.03   \n",
       "22         2.88                  0.27             1.69         3.800000  1.11   \n",
       "23         2.37                  0.26             1.46         3.930000  1.09   \n",
       "24         2.61                  0.28             1.66         3.520000  1.12   \n",
       "25         2.68                  0.47             1.92         3.580000  1.13   \n",
       "26         2.94                  0.34             1.45         4.800000  0.92   \n",
       "27         2.19                  0.27             1.35         3.950000  1.02   \n",
       "28         2.97                  0.37             1.76         4.500000  1.25   \n",
       "29         2.33                  0.26             1.98         4.700000  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "148        0.76                  0.45             1.25         8.420000  0.55   \n",
       "149        1.39                  0.34             1.14         9.400000  0.57   \n",
       "150        1.57                  0.22             1.25         8.600000  0.59   \n",
       "151        1.36                  0.24             1.26        10.800000  0.48   \n",
       "152        1.28                  0.26             1.56         7.100000  0.61   \n",
       "153        0.83                  0.61             1.87        10.520000  0.56   \n",
       "154        0.58                  0.53             1.40         7.600000  0.58   \n",
       "155        0.63                  0.61             1.55         7.900000  0.60   \n",
       "156        0.83                  0.48             1.56         9.010000  0.57   \n",
       "157        0.58                  0.63             1.14         7.500000  0.67   \n",
       "158        1.31                  0.53             2.70        13.000000  0.57   \n",
       "159        1.10                  0.52             2.29        11.750000  0.57   \n",
       "160        0.92                  0.50             1.04         7.650000  0.56   \n",
       "161        0.56                  0.50             0.80         5.880000  0.96   \n",
       "162        0.60                  0.60             0.96         5.580000  0.87   \n",
       "163        0.70                  0.40             0.94         5.280000  0.68   \n",
       "164        0.68                  0.41             1.03         9.580000  0.70   \n",
       "165        0.47                  0.52             1.15         6.620000  0.78   \n",
       "166        0.92                  0.43             1.46        10.680000  0.85   \n",
       "167        0.66                  0.40             0.97        10.260000  0.72   \n",
       "168        0.84                  0.39             1.54         8.660000  0.74   \n",
       "169        0.96                  0.27             1.11         8.500000  0.67   \n",
       "170        0.49                  0.40             0.73         5.500000  0.66   \n",
       "171        0.51                  0.48             0.64         9.899999  0.57   \n",
       "172        0.70                  0.44             1.24         9.700000  0.62   \n",
       "173        0.61                  0.52             1.06         7.700000  0.64   \n",
       "174        0.75                  0.43             1.41         7.300000  0.70   \n",
       "175        0.69                  0.43             1.35        10.200000  0.59   \n",
       "176        0.68                  0.53             1.46         9.300000  0.60   \n",
       "177        0.76                  0.56             1.35         9.200000  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  TARGET  \n",
       "0                            3.92   1065.0       0  \n",
       "1                            3.40   1050.0       0  \n",
       "2                            3.17   1185.0       0  \n",
       "3                            3.45   1480.0       0  \n",
       "4                            2.93    735.0       0  \n",
       "5                            2.85   1450.0       0  \n",
       "6                            3.58   1290.0       0  \n",
       "7                            3.58   1295.0       0  \n",
       "8                            2.85   1045.0       0  \n",
       "9                            3.55   1045.0       0  \n",
       "10                           3.17   1510.0       0  \n",
       "11                           2.82   1280.0       0  \n",
       "12                           2.90   1320.0       0  \n",
       "13                           2.73   1150.0       0  \n",
       "14                           3.00   1547.0       0  \n",
       "15                           2.88   1310.0       0  \n",
       "16                           2.65   1280.0       0  \n",
       "17                           2.57   1130.0       0  \n",
       "18                           2.82   1680.0       0  \n",
       "19                           3.36    845.0       0  \n",
       "20                           3.71    780.0       0  \n",
       "21                           3.52    770.0       0  \n",
       "22                           4.00   1035.0       0  \n",
       "23                           3.63   1015.0       0  \n",
       "24                           3.82    845.0       0  \n",
       "25                           3.20    830.0       0  \n",
       "26                           3.22   1195.0       0  \n",
       "27                           2.77   1285.0       0  \n",
       "28                           3.40    915.0       0  \n",
       "29                           3.59   1035.0       0  \n",
       "..                            ...      ...     ...  \n",
       "148                          1.62    650.0       2  \n",
       "149                          1.33    550.0       2  \n",
       "150                          1.30    500.0       2  \n",
       "151                          1.47    480.0       2  \n",
       "152                          1.33    425.0       2  \n",
       "153                          1.51    675.0       2  \n",
       "154                          1.55    640.0       2  \n",
       "155                          1.48    725.0       2  \n",
       "156                          1.64    480.0       2  \n",
       "157                          1.73    880.0       2  \n",
       "158                          1.96    660.0       2  \n",
       "159                          1.78    620.0       2  \n",
       "160                          1.58    520.0       2  \n",
       "161                          1.82    680.0       2  \n",
       "162                          2.11    570.0       2  \n",
       "163                          1.75    675.0       2  \n",
       "164                          1.68    615.0       2  \n",
       "165                          1.75    520.0       2  \n",
       "166                          1.56    695.0       2  \n",
       "167                          1.75    685.0       2  \n",
       "168                          1.80    750.0       2  \n",
       "169                          1.92    630.0       2  \n",
       "170                          1.83    510.0       2  \n",
       "171                          1.63    470.0       2  \n",
       "172                          1.71    660.0       2  \n",
       "173                          1.74    740.0       2  \n",
       "174                          1.56    750.0       2  \n",
       "175                          1.56    835.0       2  \n",
       "176                          1.62    840.0       2  \n",
       "177                          1.60    560.0       2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl = data.corr('pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ash                             0.049643\n",
       "magnesium                       0.209179\n",
       "color_intensity                 0.265668\n",
       "alcohol                         0.328222\n",
       "malic_acid                      0.437776\n",
       "nonflavanoid_phenols            0.489109\n",
       "proanthocyanins                 0.499130\n",
       "alcalinity_of_ash               0.517859\n",
       "hue                             0.617369\n",
       "proline                         0.633717\n",
       "total_phenols                   0.719163\n",
       "od280/od315_of_diluted_wines    0.788230\n",
       "flavanoids                      0.847498\n",
       "TARGET                          1.000000\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(correl['TARGET']).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"flavanoids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27795546160>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, Y, 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.min()) / (X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = (Y - Y.min()) / (Y.max() - Y.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x277955a3278>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, Y, 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(X)\n",
    "y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyp(a, x, b):\n",
    "    return (1/(1 + np.exp(1*(a*x +b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(a, x, b, y):\n",
    "    e = 0\n",
    "    m = len(x)\n",
    "    \n",
    "    for i in range(m):\n",
    "        e += (y[i] * np.log(hyp(a, x[i], b))) - (1 - y[i])*(np.log(hyp(a, x[i], b)))\n",
    "        \n",
    "    return (1/m) * e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_grad(a, x, b, y, learning_rate):\n",
    "    grad_a = 0\n",
    "    grad_b = 0\n",
    "    m = len(x)\n",
    "    \n",
    "    for i in range(m):\n",
    "        grad_a += (hyp(a, x[i], b) - y[i]) * x[i]\n",
    "        grad_b += (hyp(a, x[i], b) - y[i])\n",
    "        \n",
    "    a = a - grad_a*learning_rate\n",
    "    b = b - grad_b*learning_rate\n",
    "    \n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descnd(init_a, x, init_b, y, iteration, learning_rate):\n",
    "    a = init_a\n",
    "    b = init_b\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        e = error(a, x, b, y)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f\"error : {e}, a : {a}, b : {b}\")\n",
    "            \n",
    "        a, b = step_grad(a, x, b, y, learning_rate)\n",
    "        \n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_distance(train_point, given_point):\n",
    "    distance = np.sum((train_point-given_point)**2)\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance_from_all(all_points, given_point, predictions):\n",
    "    all_distances = []\n",
    "    for i, each in enumerate(all_points):\n",
    "        distance = euclid_distance(each, given_point)\n",
    "        all_distances.append((distance,int(predictions[i])))\n",
    "    all_distances.sort(key=lambda tup: tup[0])\n",
    "    return all_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(distances, count):\n",
    "    return distances[:count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(all_points, given_point, predictions):\n",
    "    distances = calc_distance_from_all(all_points,given_point,predictions)\n",
    "    neighbours = get_neighbours(distances, 4)\n",
    "    \n",
    "    op = [row[-1] for row in neighbours]\n",
    "    prediction = max(set(op), key=op.count)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(basex, basey, testx, testy):\n",
    "    correct = 0 \n",
    "    \n",
    "    for i in range(len(testx)):\n",
    "        p = predict(basex, testx[i], basey)\n",
    "        if p == testy[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    return f\"Accuracy: {correct*100/len(testy)}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "learning_rate = 0.001\n",
    "iteration = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error : 0.05369449990253097, a : 0, b : 0\n",
      "error : 0.0, a : -36.424762624272226, b : -73.32897351689827\n",
      "error : 0.0, a : -73.95851789853484, b : -149.82897351689812\n",
      "error : 0.0, a : -111.49227317280267, b : -226.32897351690812\n",
      "error : 0.0, a : -149.0260284470705, b : -302.8289735169181\n",
      "error : 0.0, a : -186.55978372133833, b : -379.3289735169281\n",
      "error : 0.0, a : -224.09353899560617, b : -455.8289735169381\n",
      "error : 0.0, a : -261.62729426986976, b : -532.328973516948\n",
      "error : 0.0, a : -299.1610495441092, b : -608.8289735169581\n",
      "error : 0.0, a : -336.6948048183486, b : -685.3289735169681\n",
      "error : 0.0, a : -374.228560092588, b : -761.8289735169781\n",
      "error : 0.0, a : -411.7623153668274, b : -838.3289735169881\n",
      "error : 0.0, a : -449.2960706410668, b : -914.8289735169981\n",
      "error : 0.0, a : -486.82982591530623, b : -991.3289735170081\n",
      "error : 0.0, a : -524.3635811895457, b : -1067.828973516953\n",
      "error : 0.0, a : -561.8973364637851, b : -1144.3289735168494\n",
      "error : 0.0, a : -599.4310917380245, b : -1220.8289735167457\n",
      "error : 0.0, a : -636.9648470122639, b : -1297.328973516642\n",
      "error : 0.0, a : -674.4986022865033, b : -1373.8289735165383\n",
      "error : 0.0, a : -712.0323575607428, b : -1450.3289735164346\n"
     ]
    }
   ],
   "source": [
    "final_a, final_b = descnd(a, x_train, b, y_train, iteration, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x277956410b8>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, hyp(final_a, x_train, final_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(final_a, x_train, final_b, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 52.77777777777778%'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
